{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# What is PyTorch?\n",
    "\n",
    "It’s a Python-based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "\n",
    "-  A replacement for NumPy to use the power of GPUs\n",
    "-  a deep learning research platform that provides maximum flexibility\n",
    "   and speed\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch, matplotlib, numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>An uninitialized matrix is declared,\n",
    "    but does not contain definite known\n",
    "    values before it is used. When an\n",
    "    uninitialized matrix is created,\n",
    "    whatever values were in the allocated\n",
    "    memory at the time will appear as the initial values.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 5x3 matrix, uninitialized:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.9354e-38,  4.5747e-41,  9.9355e-38],\n",
      "        [ 4.5747e-41,  9.3948e-38,  4.5747e-41],\n",
      "        [-1.0976e-11,  3.0662e-41,  1.0089e-42],\n",
      "        [ 0.0000e+00,  8.9683e-44,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.8545e+25]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized matrix:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1508, 0.7179, 0.7431],\n",
      "        [0.6917, 0.9186, 0.1138],\n",
      "        [0.5101, 0.3057, 0.8739],\n",
      "        [0.2368, 0.5248, 0.7228],\n",
      "        [0.2571, 0.9209, 0.2342]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a matrix filled zeros and of dtype long:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor directly from data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or create a tensor based on an existing tensor. These methods reuse properties of the input tensor, e.g. dtype, unless\n",
    "new values are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.3911, -1.2004, -1.1698],\n",
      "        [-0.0216, -0.3579, -1.7279],\n",
      "        [ 0.1533,  1.5864, -0.4136],\n",
      "        [ 1.2997,  1.2311,  0.9447],\n",
      "        [ 1.1638, -0.6565,  0.3091]])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5,3,dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x,dtype=torch.float)   # override dtype\n",
    "print(x)                                    # result has the same size\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations\n",
    "\n",
    "There are multiple syntaxes for operations. In the following example, we will take a look at the addition operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9288, -0.5901, -1.0661],\n",
      "        [ 0.1068,  0.2418, -1.0126],\n",
      "        [ 0.6101,  2.5262,  0.5338],\n",
      "        [ 1.8472,  2.2079,  1.8164],\n",
      "        [ 1.4233, -0.4811,  0.5903]])\n",
      "tensor([[ 0.9288, -0.5901, -1.0661],\n",
      "        [ 0.1068,  0.2418, -1.0126],\n",
      "        [ 0.6101,  2.5262,  0.5338],\n",
      "        [ 1.8472,  2.2079,  1.8164],\n",
      "        [ 1.4233, -0.4811,  0.5903]])\n",
      "tensor([[ 0.9288, -0.5901, -1.0661],\n",
      "        [ 0.1068,  0.2418, -1.0126],\n",
      "        [ 0.6101,  2.5262,  0.5338],\n",
      "        [ 1.8472,  2.2079,  1.8164],\n",
      "        [ 1.4233, -0.4811,  0.5903]])\n",
      "tensor([[ 0.9288, -0.5901, -1.0661],\n",
      "        [ 0.1068,  0.2418, -1.0126],\n",
      "        [ 0.6101,  2.5262,  0.5338],\n",
      "        [ 1.8472,  2.2079,  1.8164],\n",
      "        [ 1.4233, -0.4811,  0.5903]])\n"
     ]
    }
   ],
   "source": [
    "# Syntax 1\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "\n",
    "# Syntax 2\n",
    "print(torch.add(x, y))\n",
    "\n",
    "# Syntax 3\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "# Syntax 4\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an _.\n",
    "    For example: x.copy_(y), x.t_() will change x.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to resize/reshape tensor, you can use ``torch.view``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a one-element tensor, use ``.item()`` to get the value as a Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0288])\n",
      "0.028803542256355286\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Bridge\n",
    "\n",
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "\n",
    "The Torch Tensor and NumPy array will share their underlying memory\n",
    "locations (if the Torch Tensor is on CPU), and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the numpy array changed in value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting NumPy Array to Torch Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA Tensors\n",
    "------------\n",
    "\n",
    "Tensors can be moved onto any device using the ``.to`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell only if CUDA is available\n",
    "# We will use torch.device objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings \".to(\"cuda\")\"\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # .to can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 7.8971e-37],\n",
      "        [4.5747e-41, 8.9683e-44, 0.0000e+00]]) \n",
      " tensor([[1., 2.],\n",
      "        [4., 5.]]) \n",
      " tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "v1 = torch.Tensor(2,3)           # An un-initialized torch.FloatTensor of size 2x3\n",
    "v2 = torch.Tensor([[1,2],[4,5]]) # A Tensor initialized with a specific array\n",
    "v3 = torch.LongTensor([1,2,3])   # A Tensor of type Long\n",
    "print(v1,\"\\n\",v2,\"\\n\",v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.rand(2,3)             # Initialize with random number (uniform distribution)\n",
    "v = torch.randn(2,3)            # With normal distribution (SD=1, mean=0)\n",
    "v = torch.randperm(4)           # Size 4. Random permutation of integers from 0 to 3\n",
    "eye = torch.eye(3)              # Create an identity 3x3 tensor\n",
    "v = torch.ones(10)              # A tensor of size 10 containing all ones\n",
    "v = torch.ones(2,1,2,1)         # Size 2x1x2x1\n",
    "v = torch.ones_like(eye)        # A tensor with same shape as eye. Fill it with 1.\n",
    "v = torch.zeros(10)             # A tensor of size 10 containing all zeros\n",
    "v = torch.arange(5)             # similar to range(5) but creating a Tensor\n",
    "v = torch.arange(0,5,step=1)    # Size 5. Similar to range(0, 5, 1)\n",
    "\n",
    "v = torch.linspace(1,10,steps=10)            # Create a Tensor with 10 linear points for (1,10) inclusively\n",
    "v = torch.logspace(start=-10,end=10,steps=5) # Size 5: 1.0e-10 1.0e-05 1.0e+00, 1.0e+05, 1.0e+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.ones(3, 3)\n",
    "print(v)\n",
    "v[1].fill_(2)\n",
    "print(v)\n",
    "v[2].fill_(3)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing, Slicing, Joining, Mutating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation\n",
    "torch.cat((x,x,x),0) # Concatenate in the 0 dimension\n",
    "\n",
    "# Gather element\n",
    "# torch.gather(input, dim, index, out=None)\n",
    "r = torch.gather(v,1,torch.LongTensor([[0,1],[1,0],[2,1]]))\n",
    "\n",
    "# Split an array into 3 chunks\n",
    "r = torch.chunk(v, 3)\n",
    "\n",
    "# Index select\n",
    "indices = torch.LongTensor([0,2])\n",
    "r = torch.index_select(v,1,indices) # Select element 0 and 2 for each dimension 1.\n",
    "\n",
    "# Masked select\n",
    "mask = v.ge(3)\n",
    "r = torch.masked_select(v,mask)\n",
    "\n",
    "# [i,j] index for non-zero elements\n",
    "r = torch.nonzero(v)\n",
    "\n",
    "# Split an array into chunks of at most size 2\n",
    "r = torch.split(v,2)\n",
    "\n",
    "t = torch.ones(2,1,2,1) # Size 2x1x2x1\n",
    "r = torch.squeeze(t)    # Size 2x2\n",
    "r = torch.squeeze(t,1)  # Squeeze dimension 1: Size 2x2x1\n",
    "\n",
    "# Stack\n",
    "r = torch.stack((v,v))\n",
    "\n",
    "# Flatten a TensorFlow and return elements with given indexes\n",
    "r = torch.take(v,torch.LongTensor([0,4,2]))\n",
    "\n",
    "# Transpose dim 0 and 1\n",
    "r = torch.transpose(v,0,1)\n",
    "\n",
    "# Un-squeeze a dimension\n",
    "x = torch.Tensor([1,2,3])\n",
    "r = torch.unsqueeze(x,0)    # Size: 1x3\n",
    "r = torch.unsqueeze(x,1)    # Size: 3x1\n",
    "\n",
    "c = torch.ByteTensor([0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform distributed\n",
    "r = torch.Tensor(2,2).uniform_(0,1)\n",
    "\n",
    "# bernoulli\n",
    "r = torch.bernoulli(r)   # Size: 2x2. Bernoulli with probability p stored in elements of r\n",
    "\n",
    "# Multinomial\n",
    "w = torch.Tensor([0,4,8,2]) # Create a tensor of weights\n",
    "r = torch.multinomial(w,4,replacement=True) # Size 4: 3, 2, 1, 2\n",
    "\n",
    "# Normal distribution\n",
    "# From 10 means and SD\n",
    "r = torch.distributions.normal.Normal(loc=torch.tensor([0.0]),scale=torch.tensor([1.0])) # Size 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduction operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate sum\n",
    "r = torch.cumsum(v,dim=0)\n",
    "\n",
    "# L-P norm\n",
    "r = torch.dist(v,v+3,p=2)  # L-2 norm: ((3^2)*9)^(1/2) = 9.0\n",
    "\n",
    "r = torch.mean(v, 1)         # Size 3: Mean in dim 1\n",
    "r = torch.mean(v, 1, True)   # Size 3x1 since keep dimension = True\n",
    "\n",
    "r = torch.sum(v, 1)          # Sum over dim 1\n",
    "r = torch.sum(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size 3x3: Element-wise comparison\n",
    "r = torch.eq(v,v)\n",
    "# k-th element (start from 1) ascending order with corresponding index\n",
    "r = torch.kthvalue(v,2)\n",
    "\n",
    "r = torch.max(v,1)\n",
    "r = torch.sort(v,1)\n",
    "r = torch.topk(v,1)\n",
    "\n",
    "m1 = torch.ones(3,5)\n",
    "m2 = torch.ones(3,5)\n",
    "v1 = torch.ones(3)\n",
    "\n",
    "# Cross product, Size 3x5\n",
    "r = torch.cross(m1,m2)\n",
    "# Diagonal matrix, Size 3x3\n",
    "r = torch.diag(v1)\n",
    "\n",
    "# Histogram\n",
    "torch.histc(torch.FloatTensor([1,2,1]),bins=4,min=0,max=3)\n",
    "\n",
    "# Renormalize\n",
    "r = torch.renorm(v, 1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix, vector products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0873,  0.0981],\n",
      "        [ 6.9641, -0.6061],\n",
      "        [-1.0203, -2.8441]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix X vector, Size 2x4\n",
    "mat = torch.randn(2,4)\n",
    "vec = torch.randn(4)\n",
    "r = torch.mv(mat, vec)\n",
    "\n",
    "# Matrix + Matrix X vector, Size 2\n",
    "M = torch.randn(2)\n",
    "mat = torch.randn(2,3)\n",
    "vec = torch.randn(3)\n",
    "r = torch.addmv(M,mat,vec)\n",
    "\n",
    "# Matrix x Matrix, Size 2x4\n",
    "mat1 = torch.randn(2,3)\n",
    "mat2 = torch.randn(3,4)\n",
    "r = torch.mm(mat1,mat2)\n",
    "\n",
    "# Matrix + Matrix X Matrix, Size 3x4\n",
    "M = torch.randn(3,4)\n",
    "mat1 = torch.randn(3,2)\n",
    "mat2 = torch.randn(2,4)\n",
    "r = torch.addmm(M,mat1,mat2)\n",
    "\n",
    "# Dot product of 2 tensors\n",
    "r = torch.dot(torch.Tensor([4,2]),torch.Tensor([3,1])) # 14\n",
    "\n",
    "# Outer product of 2 vectors, Size 3x2\n",
    "v1 = torch.arange(1,4)\n",
    "v2 = torch.arange(1,3)\n",
    "r = torch.ger(v1,v2)\n",
    "\n",
    "# Batch Matrix x Matrix, Size 10x3x5\n",
    "batch1 = torch.randn(10,3,4)\n",
    "batch2 = torch.randn(10,4,5)\n",
    "r = torch.bmm(batch1,batch2)\n",
    "\n",
    "# Batch Matrix + Matrix x Matrix\n",
    "# Performs a batch matrix-matrix product\n",
    "# 3x4 + (5x3x4 X 5x4x2 ) -> 5x3x2\n",
    "M = torch.randn(3,2)\n",
    "batch1 = torch.randn(5,3,4)\n",
    "batch2 = torch.randn(5,4,2)\n",
    "r = torch.addbmm(M,batch1,batch2)\n",
    "\n",
    "# Move Tensors to GPU\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
